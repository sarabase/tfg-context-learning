{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion-MNIST model testing\n",
        "In this notebook we will test if the results obtained with MNIST are also valid with Fashion-MNIST"
      ],
      "metadata": {
        "id": "-U-8WYW3REiE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2pN_-iDRDSl"
      },
      "source": [
        "# Make the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf--WJEQRDSs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyHVz5tsRDSt"
      },
      "source": [
        "# # Import and preprocess the Fashion-MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra2gi4UKRDSu",
        "outputId": "0685f647-9b7c-498d-caec-f187495d2b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Xtrain shape: (60000, 28, 28)\n",
            "ytrain shape: (60000,)\n",
            "Xtest shape: (10000, 28, 28)\n",
            "ytest shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "(Xtrain_orig, ytrain_orig), (Xtest_orig, ytest_orig) = fashion_mnist.load_data()\n",
        "\n",
        "Xtrain = Xtrain_orig.astype('float32')/255.\n",
        "Xtest = Xtest_orig.astype('float32')/255.\n",
        "\n",
        "ytrain = ytrain_orig\n",
        "ytest = ytest_orig\n",
        "\n",
        "print (\"Xtrain shape: \" + str(Xtrain.shape))\n",
        "print (\"ytrain shape: \" + str(ytrain.shape))\n",
        "\n",
        "print (\"Xtest shape: \" + str(Xtest.shape))\n",
        "print (\"ytest shape: \" + str(ytest.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7_1ZgOKRDSu"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im7PtsHaRDSw"
      },
      "outputs": [],
      "source": [
        "def create_random_set(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We now want our examples to have the following shape: (N, X_train[1], X_train[2], (strip_size+1)*3 donde\n",
        "    #And create the expected labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 1])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = tf.expand_dims(X[X_groups[i][j]], axis=-1)\n",
        "        X_processed[i, strip_size, :, :, :] = tf.expand_dims(X[X_groups[i][strip_size]], axis=-1)\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbrTsLx3RDSx"
      },
      "outputs": [],
      "source": [
        "def create_random_set_RGB(X, y, strip_size=4, set_size=60000):\n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We now want our examples to have the following shape: (N, X_train[1], X_train[2], (strip_size+1)*3 donde\n",
        "    ##And create the expected labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = X[X_groups[i][j]]\n",
        "        X_processed[i, strip_size, :, :, :] = X[X_groups[i][strip_size]]\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoIafbdFRDSz"
      },
      "outputs": [],
      "source": [
        "def create_random_data_sets(X, y, Xt, yt, strip_size, training_size=30000, test_size=2000, RGB=False):\n",
        "    if RGB:\n",
        "        Xtrain, ytrain = create_random_set_RGB(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
        "        Xtest, ytest = create_random_set_RGB(Xt, yt, strip_size, set_size=test_size)\n",
        "    else:\n",
        "        Xtrain, ytrain = create_random_set(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
        "        Xtest, ytest = create_random_set(Xt, yt, strip_size, set_size=test_size)\n",
        "    \n",
        "    print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "    print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "    print (\"Validation examples classified as 0: \" + str(len(np.where(yval==0)[0])))\n",
        "    print (\"Validation examples classified as 1: \" + str(len(np.where(yval==1)[0])))\n",
        "    print (\"Test examples classified as 0: \" + str(len(np.where(ytest==0)[0])))\n",
        "    print (\"Test examples classified as 1: \" + str(len(np.where(ytest==1)[0])))\n",
        "    \n",
        "    return Xtrain, Xval, Xtest, ytrain, yval, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKiQDhH-RDSz"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, lr=1e-3, batch_size=32, model_save_name=\"best_model\"):\n",
        "\n",
        "    #Define callbacks\n",
        "    #Save the best model\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, model_save_name)\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    \n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "        mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "    #Add early stopping\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "    #Reduce learning rate on plateau\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.65, patience=5, min_lr=1e-5)\n",
        "    callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "    #Compile and fit the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
        "                  loss='binary_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(Xtrain, ytrain,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=80,\n",
        "                        validation_data=(Xval, yval),\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\"\"\"\n",
        "    \n",
        "    model.load_weights(filepath)\n",
        "    ypredict = model.predict(Xtest)\n",
        "    #ypredict = tf.squeeze(ypredict).numpy()\n",
        "    #print(ypredict)\n",
        "    #ypredict_round = [round(x) for x in ypredict]\n",
        "    score = model.evaluate(Xtest, ytest, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    \n",
        "    #cm = confusion_matrix(ytest, ypredict)\n",
        "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    #disp.plot()\n",
        "    #plt.show()\n",
        "    \n",
        "    return score[1], model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Trf4NBxRDS0"
      },
      "outputs": [],
      "source": [
        "def see_embeddings(model, X, y, save_name, preprocess_func, RGB):\n",
        "    embeddings_per_class = 10\n",
        "    classes = 10\n",
        "    # Buscamos 3 imagenes de cada clase\n",
        "    #Creamos una lista de listas donde cada sublista contiene los índices de la imágenes de un número\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(classes)]\n",
        "    \n",
        "    if RGB:\n",
        "        images = np.zeros((classes*embeddings_per_class, X.shape[1], X.shape[2], 3))\n",
        "        for i in range(classes):\n",
        "            list_of_indexes = random.choices(list_indices_by_number[i], k=embeddings_per_class)\n",
        "            images[embeddings_per_class*i:(i+1)*embeddings_per_class, :, :, :] = X[list_of_indexes]\n",
        "    else:\n",
        "        images = np.zeros((classes*embeddings_per_class, X.shape[1], X.shape[2], 1))\n",
        "        for i in range(classes):\n",
        "            list_of_indexes = random.choices(list_indices_by_number[i], k=embeddings_per_class)\n",
        "            images[embeddings_per_class*i:(i+1)*embeddings_per_class, :, :, :] = tf.expand_dims(X[list_of_indexes], axis=-1)\n",
        "\n",
        "    if preprocess_func:\n",
        "        prep_images = preprocess_func(images)\n",
        "        encoded_images = model.encoder(prep_images).numpy()\n",
        "    else:\n",
        "        encoded_images = model.encoder(images).numpy()\n",
        "    \n",
        "    plt.figure(figsize=(15, 30))\n",
        "\n",
        "    m = embeddings_per_class\n",
        "    n = classes\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            ax = plt.subplot(m, n, n*i+j+1)\n",
        "            plt.imshow(tf.expand_dims(encoded_images[n*i+j], axis=-1))\n",
        "            plt.title('Class: ' + str(i), fontsize=16)\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "    plt.suptitle('Image embeddings per class', fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    plt.savefig(save_name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI5FYEYVRDS1"
      },
      "outputs": [],
      "source": [
        "def save_to_db(db_name, column_name, list_to_save):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    df[column_name] = list_to_save\n",
        "    df.to_csv(db_name + '.csv', index=False)\n",
        "\n",
        "def create_db(db_name):\n",
        "    df = pd.DataFrame()\n",
        "    df.to_csv(db_name + '.csv', index=True)\n",
        "\n",
        "def plot_db_columns(db_name, title, xlabel, ylabel, save_name):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    # plot lines\n",
        "    x = [i for i in range(2, 11)]\n",
        "    plt.figure(figsize=(9,7))\n",
        "    \n",
        "    for column in df:\n",
        "        if (column != 'Unnamed: 0'):\n",
        "            plt.plot(x, df[column], label = column)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(axis = 'y', color = 'gray', linestyle = '--', linewidth = 0.5)\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.savefig(save_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA_pP9JZRDS1"
      },
      "outputs": [],
      "source": [
        "def run_model(X, y, Xt, yt, model_class, latent_dim, model_save_name, db_name, column_name, preprocess_func, preprocess_before, num_iterations=3, RGB=True, pre_model=None, lr=1e-3):\n",
        "    \n",
        "    #Preprocess data\n",
        "    if preprocess_before:\n",
        "        X_processed = preprocess_func(X)\n",
        "        Xt_processed = preprocess_func(Xt)\n",
        "    else:\n",
        "        X_processed = X\n",
        "        Xt_processed = Xt\n",
        "        \n",
        "    accuracy_per_strip_size = []\n",
        "    for strip_size in range(1, 10):\n",
        "        print('-------------------' + str(strip_size) + '-------------------')\n",
        "        channels = strip_size + 1\n",
        "        accuracy_per_iteration = []\n",
        "        for i in range(num_iterations):\n",
        "            print('--------------Iteration ' + str(i+1) + '--------------')\n",
        "            Xtrain, Xval, Xtest, ytrain, yval, ytest = create_random_data_sets(X_processed, y, Xt_processed, yt, strip_size, RGB=RGB)\n",
        "            tf.keras.backend.clear_session()\n",
        "            if pre_model:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3]), pre_model)\n",
        "            else:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3])) \n",
        "            score, model = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, lr=lr, batch_size=32, model_save_name=model_save_name)\n",
        "            if i == (num_iterations-1):\n",
        "                embedding_file_path = os.path.join('embedding_images', model_save_name + str(channels) + '.png')\n",
        "                see_embeddings(model, X, y, embedding_file_path, preprocess_func, RGB)\n",
        "            accuracy_per_iteration.append(score)\n",
        "            del Xtrain\n",
        "            del Xval\n",
        "            del Xtest\n",
        "            del ytrain\n",
        "            del yval\n",
        "            del ytest\n",
        "            del model\n",
        "        accuracy_per_strip_size.append(np.mean(accuracy_per_iteration))\n",
        "    save_to_db(db_name, column_name, accuracy_per_strip_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_tBK00QRDS1"
      },
      "source": [
        "# Build models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSql7EfZRDS2"
      },
      "outputs": [],
      "source": [
        "os.mkdir('embedding_images') #Only run this line of no directory already called embedding images is already created\n",
        "create_db('mnist_fashion_32')\n",
        "create_db('mnist_fashion_10')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build models based on the maximum operation for combining the context images\n",
        "We will test the models with two different encoder blocks:\n",
        "- If the model is named ---1, then it will be using the same encoder we used with the MNIST dataset. \n",
        "- If the model is named ---2, then it will be using a new encoder better prepared for the Fashion-MNIST dataset."
      ],
      "metadata": {
        "id": "Soi7MfPcTV_-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TPIU32VRDS3"
      },
      "source": [
        "### Models with the dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6fZU7XTRDS3"
      },
      "outputs": [],
      "source": [
        "class DotConv1(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(DotConv1, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHbgQWKrRDS4"
      },
      "outputs": [],
      "source": [
        "class DotConv2(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(DotConv2, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp_5UUmdRDS4"
      },
      "source": [
        "### Models with the dot product and a dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cdwDYVpRDS5"
      },
      "outputs": [],
      "source": [
        "class DotDenseConv1(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(DotDenseConv1, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)  \n",
        "        ])\n",
        "        \n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Dense(1, input_shape=[1])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        dot = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        y_predict = self.classifier(dot)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv18jpz0RDS5"
      },
      "outputs": [],
      "source": [
        "class DotDenseConv2(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(DotDenseConv2, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Dense(1, input_shape=[1])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        dot = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        y_predict = self.classifier(dot)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P23AgjkRDS5"
      },
      "source": [
        "### Models with a dense classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgvQ_bLTRDS6"
      },
      "outputs": [],
      "source": [
        "class MaxClassifier1(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(MaxClassifier1, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EUyT_OHRDS6"
      },
      "outputs": [],
      "source": [
        "class MaxClassifier2(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(MaxClassifier2, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "AJ2EhIWuRDS6"
      },
      "outputs": [],
      "source": [
        "run_model(Xtrain, ytrain, Xtest, ytest, DotConv1, 32, 'DotConv1', 'mnist_fashion_32', 'DotConv1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotConv2, 32, 'DotConv2', 'mnist_fashion_32', 'DotConv2', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotDenseConv1, 32, 'DotDenseConv1', 'mnist_fashion_32', 'DotDenseConv1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotDenseConv2, 32, 'DotDenseConv2', 'mnist_fashion_32', 'DotDenseConv2', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, MaxClassifier1, 32, 'MaxClassifier1', 'mnist_fashion_32', 'MaxClassifier1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, MaxClassifier2, 32, 'MaxClassifier2', 'mnist_fashion_32', 'MaxClassifier2', None, False, num_iterations=1, RGB=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "WCOGSpciRDS7"
      },
      "outputs": [],
      "source": [
        "run_model(Xtrain, ytrain, Xtest, ytest, DotConv1, 10, 'DotConv1', 'mnist_fashion_10', 'DotConv1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotConv2, 10, 'DotConv2', 'mnist_fashion_10', 'DotConv2', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotDenseConv1, 10, 'DotDenseConv1', 'mnist_fashion_10', 'DotDenseConv1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, DotDenseConv2, 10, 'DotDenseConv2', 'mnist_fashion_10', 'DotDenseConv2', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, MaxClassifier1, 10, 'MaxClassifier1', 'mnist_fashion_10', 'MaxClassifier1', None, False, num_iterations=1, RGB=False)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, MaxClassifier2, 10, 'MaxClassifier2', 'mnist_fashion_10', 'MaxClassifier2', None, False, num_iterations=1, RGB=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj_T0PFSRDS9"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clsrA9UERDS9"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('mnist_fashion_32', 'Fashion MNIST model testing', 'Strip size', 'Accuracy', 'mnist_fashion_32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgzIyZ1bRDS9"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('mnist_fashion_10', 'Fashion MNIST model testing', 'Strip size', 'Accuracy', 'mnist_fashion_10')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "mnist-fashion-model-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}