{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST model testing\n",
        "In this notebook we will be working with the MNIST dataset. We will use it to create strips of images with a maximum length of 10 images.\n",
        "The purpose of this notebook is to train a model that determines whether the last image (target iamge) in the strip contains a class that is already represented by the previous images (context images) in the strip.\n",
        "\n",
        "We will test several operations for joining the embedding obtained from the context images into one context embedding:\n",
        "- Maximum\n",
        "- Average\n",
        "- Addition\n",
        "- Dense"
      ],
      "metadata": {
        "id": "7HZldObtJIkL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ_nNhhfBhao"
      },
      "source": [
        "# Make the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx6AH6RGBhas",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import *\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRccsWVTBhat"
      },
      "source": [
        "# Import and preprocess the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onz3e3WXBhau",
        "tags": []
      },
      "outputs": [],
      "source": [
        "(Xtrain_orig, ytrain_orig), (Xtest_orig, ytest_orig) = mnist.load_data()\n",
        "\n",
        "Xtrain_norm = tf.expand_dims(Xtrain_orig.astype('float32') / 255., axis=-1)\n",
        "Xtest_norm = tf.expand_dims(Xtest_orig.astype('float32') / 255., axis=-1)\n",
        "\n",
        "ytrain_norm = ytrain_orig\n",
        "ytest_norm = ytest_orig\n",
        "\n",
        "print (\"Xtrain shape: \" + str(Xtrain_norm.shape))\n",
        "print (\"ytrain shape: \" + str(ytrain_norm.shape))\n",
        "\n",
        "print (\"Xtest shape: \" + str(Xtest_norm.shape))\n",
        "print (\"ytest shape: \" + str(ytest_norm.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPNsrDVIBhav"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb0Tf-tTBhaw"
      },
      "outputs": [],
      "source": [
        "#Allow for repetitions in the context images\n",
        "def create_set(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We now want our examples to have the following shape: (N, X_train[1], X_train[2], (strip_size+1)*3 where\n",
        "    #And create the expected labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 1])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        #Creamos los canales para cada imagen\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = X[X_groups[i][j]]\n",
        "        #Añadimos la última imagen al último canal\n",
        "        X_processed[i, strip_size, :, :, :] = X[X_groups[i][strip_size]]\n",
        "        #Creamos el expected output para cada tira\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAo2_ZFYBhay"
      },
      "outputs": [],
      "source": [
        "def create_data_sets(X, y, Xt, yt, strip_size, training_size=50000, test_size=10000):\n",
        "    Xtrain, ytrain = create_set(X, y, strip_size, set_size=training_size)\n",
        "    Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
        "    Xtest, ytest = create_set(Xt, yt, strip_size, set_size=test_size)\n",
        "    \n",
        "    \"\"\"print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "    print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "    print (\"Validation examples classified as 0: \" + str(len(np.where(yval==0)[0])))\n",
        "    print (\"Validation examples classified as 1: \" + str(len(np.where(yval==1)[0])))\n",
        "    print (\"Test examples classified as 0: \" + str(len(np.where(ytest==0)[0])))\n",
        "    print (\"Test examples classified as 1: \" + str(len(np.where(ytest==1)[0])))\"\"\"\n",
        "    \n",
        "    return Xtrain, Xval, Xtest, ytrain, yval, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw3fmFnzBhay"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"best_model\"):\n",
        "    \n",
        "    #Define callbacks\n",
        "    #Save the best model\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, model_save_name)\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "        mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "    #Add early stopping\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=7, verbose = 0)\n",
        "    #Reduce learning rate on plateau\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "    callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "    \n",
        "    #Compile and fit the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(Xtrain, ytrain,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=60,\n",
        "                        validation_data=(Xval, yval),\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\"\"\"\n",
        "    \n",
        "    model.load_weights(filepath)\n",
        "    ypredict = model.predict(Xtest)\n",
        "    #ypredict = tf.squeeze(ypredict).numpy()\n",
        "    #print(ypredict)\n",
        "    #ypredict_round = [round(x) for x in ypredict]\n",
        "    score = model.evaluate(Xtest, ytest, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    \n",
        "    #cm = confusion_matrix(ytest, ypredict)\n",
        "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    #disp.plot()\n",
        "    #plt.show()\n",
        "    \n",
        "    return score[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mPCRJ0GBha0"
      },
      "outputs": [],
      "source": [
        "def save_to_db(db_name, column_name, list_to_save):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    df[column_name] = list_to_save\n",
        "    df.to_csv(db_name + '.csv', index=False)\n",
        "\n",
        "def create_db(db_name):\n",
        "    df = pd.DataFrame()\n",
        "    df.to_csv(db_name + '.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaY4CtTnBha1"
      },
      "outputs": [],
      "source": [
        "def plot_db_columns(db_name, title, xlabel, ylabel, save_name):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    # plot lines\n",
        "    x = [i for i in range(1, 10)]\n",
        "    plt.figure(figsize=(9,7))\n",
        "    \n",
        "    for column in df:\n",
        "        if (column != 'Unnamed: 0'):\n",
        "            plt.plot(x, df[column], label = column)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend()\n",
        "    plt.grid(axis = 'y', color = 'gray', linestyle = '--', linewidth = 0.5)\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.savefig(save_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHNnGbFjBha2"
      },
      "outputs": [],
      "source": [
        "create_db('join_operations')\n",
        "create_db('max_operations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPc0KqHsBha2"
      },
      "source": [
        "# First models to test the combining operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwV4kKYoBha6"
      },
      "source": [
        "## Maximum operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj8iqHK4Bha7"
      },
      "outputs": [],
      "source": [
        "class Max(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(Max, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu', input_shape=[self.latent_dim, 2]),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_XKmEV3Bha8"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_max= []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Max(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"max_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_max.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'max_32', accuracy_per_strip_size_max)\n",
        "save_to_db('max_operations', 'max_32', accuracy_per_strip_size_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br_vfwi5Bha8"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_max= []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Max(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"max_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_max.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'max_10', accuracy_per_strip_size_max)\n",
        "save_to_db('max_operations', 'max_10', accuracy_per_strip_size_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmC1xWX8Bha9"
      },
      "source": [
        "## Average operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzDMy5ZYBha-"
      },
      "outputs": [],
      "source": [
        "class Avg(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(Avg, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu', input_shape=[self.latent_dim]),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            avg_image = layers.Average()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            avg_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([avg_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e12EBq5rBha-"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_avg = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Avg(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"avg_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_avg.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'avg_32', accuracy_per_strip_size_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek_cXlvGBha_"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_avg = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Avg(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"avg_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_avg.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'avg_10', accuracy_per_strip_size_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leBzIhzhBhbA"
      },
      "source": [
        "## Addition operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJzczIl3BhbA"
      },
      "outputs": [],
      "source": [
        "class Sum(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(Sum, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu', input_shape=[self.latent_dim]),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            add_image = layers.Add()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            add_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([add_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I470bxxBhbB"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_sum = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Sum(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"sum_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_sum.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'sum_32', accuracy_per_strip_size_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef-y0Ge7BhbB"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_sum = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Sum(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"sum_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_sum.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'sum_10', accuracy_per_strip_size_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0TOukDmBhbC"
      },
      "source": [
        "## Dense layer\n",
        "The idea is for the neural network to learn the best operation to join the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT-PO98kBhbC"
      },
      "outputs": [],
      "source": [
        "class Dense(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(Dense, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.connection = tf.keras.Sequential([\n",
        "            layers.Flatten(input_shape=[self.latent_dim, self.channels-1]),\n",
        "            layers.Dense(units=self.latent_dim)\n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu', input_shape=[self.latent_dim]),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            dense_image = self.connection(tf.stack([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)], axis=-1))\n",
        "        else:\n",
        "            dense_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([dense_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNRj0VeEBhbD"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_dense = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Dense(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dense_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dense.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'dense_32', accuracy_per_strip_size_dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1jP81OWBhbD"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_dense = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Dense(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dense_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dense.append(np.mean(iteration_scores))\n",
        "save_to_db('join_operations', 'dense_10', accuracy_per_strip_size_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye_uMHsZBhbE"
      },
      "source": [
        "## Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKSunWNKBhbE"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('join_operations', 'Model accuracy per strip size', 'Strip size', 'Accuracy', 'join_operations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHnfGmquBhbE"
      },
      "source": [
        "# Models for testing the classifier block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KVCfo_NBhbF"
      },
      "source": [
        "## Dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9djlISYCBhbF"
      },
      "outputs": [],
      "source": [
        "class Dot(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(Dot, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esFoPvY5BhbG"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_dot_32 = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Dot(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dot_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dot_32.append(np.mean(iteration_scores))\n",
        "save_to_db('max_operations', 'dot_32', accuracy_per_strip_size_dot_32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIynz8AOBhbG"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_dot_10 = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = Dot(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dot_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dot_10.append(np.mean(iteration_scores))\n",
        "save_to_db('max_operations', 'dot_10', accuracy_per_strip_size_dot_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0LUpRFzBhbH"
      },
      "source": [
        "## Dor product + dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xxNGOM9BhbH"
      },
      "outputs": [],
      "source": [
        "class DotDense(keras.Model):\n",
        "    def __init__(self, latent_dim, channels):\n",
        "        super(DotDense, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, input_shape=[28, 28, 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=2),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.ReLU(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Dense(1, input_shape=[1])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        dot = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        y_predict = self.classifier(dot)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aye_02FsBhbI"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "accuracy_per_strip_size_dot_dense_32 = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = DotDense(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dot_dense_model_32\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dot_dense_32.append(np.mean(iteration_scores))\n",
        "save_to_db('max_operations', 'dot_dense_32', accuracy_per_strip_size_dot_dense_32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MSTYmRSBhbI"
      },
      "outputs": [],
      "source": [
        "latent_dim = 10\n",
        "accuracy_per_strip_size_dot_dense_10 = []\n",
        "for strip_size in range(1, 10):\n",
        "    print('-------------------' + str(strip_size) + '-------------------')\n",
        "    iteration_scores = []\n",
        "    for i in range(1):\n",
        "        print('------------- Iteration ' + str(i+1) + ' -------------')\n",
        "        channels = strip_size + 1\n",
        "        Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, strip_size)\n",
        "        model = DotDense(latent_dim, channels)\n",
        "        score = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"dot_dense_model_10\")\n",
        "        iteration_scores.append(score)\n",
        "    accuracy_per_strip_size_dot_dense_10.append(np.mean(iteration_scores))\n",
        "save_to_db('max_operations', 'dot_dense_10', accuracy_per_strip_size_dot_dense_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30bjPZ40BhbJ"
      },
      "source": [
        "## Maximum and classifier\n",
        "Already ran before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqKwUhj7BhbJ"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5banTvKBhbJ"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('max_operations', 'Model accuracy per strip size', 'Strip size', 'Accuracy', 'max_operations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocv_6NxnoM71"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "30bjPZ40BhbJ"
      ],
      "machine_shape": "hm",
      "name": "mnist_model_test.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc-autonumbering": true
  },
  "nbformat": 4,
  "nbformat_minor": 0
}