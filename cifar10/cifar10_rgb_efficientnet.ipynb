{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiQz4rGYdPqQ"
      },
      "source": [
        "# Cifar10 model testing\n",
        "In this notebook we will test if working with grey-scaled images gives better results than working with RGB images. For this, we will try several techniques:\n",
        "- Flatten the three channels **(Flatten)**\n",
        "- Maximum of the three channels **(MaxChannels)**\n",
        "- Use the image with three channels **(Embedding)**\n",
        "- Convolutional layer **(Convolutional)**\n",
        "- Black and white function **(BlackWhite)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5EuIxm6dPqR"
      },
      "source": [
        "# Make the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icXI6TIXbyFW"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git\n",
        "!pip install umap-learn[plot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c7yU8GidPqS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from classification_models.tfkeras import Classifiers\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "\n",
        "import umap.umap_ as umap\n",
        "import umap.plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaqYcrOcdPqV"
      },
      "source": [
        "# Import and preprocess the Cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMQgRIgodPqV"
      },
      "outputs": [],
      "source": [
        "(Xtrain_orig, ytrain_orig), (Xtest_orig, ytest_orig) = cifar10.load_data()\n",
        "Xtrain_orig = Xtrain_orig.astype('float32')\n",
        "Xtest_orig = Xtest_orig.astype('float32')\n",
        "\n",
        "print (\"Xtrain shape: \" + str(Xtrain_orig.shape))\n",
        "print (\"ytrain shape: \" + str(ytrain_orig.shape))\n",
        "\n",
        "print (\"Xtest shape: \" + str(Xtest_orig.shape))\n",
        "print (\"ytest shape: \" + str(ytest_orig.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMf-inMvdPqZ"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEross2MdPqZ"
      },
      "outputs": [],
      "source": [
        "def create_random_set(X, y, strip_size=4, set_size=25000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We want the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, 0] = tf.squeeze(X[X_groups[i][j]])\n",
        "            X_processed[i, j:j+1, :, :, 1] = tf.squeeze(X[X_groups[i][j]])\n",
        "            X_processed[i, j:j+1, :, :, 2] = tf.squeeze(X[X_groups[i][j]])\n",
        "        X_processed[i, strip_size, :, :, 0] = tf.squeeze(X[X_groups[i][strip_size]])\n",
        "        X_processed[i, strip_size, :, :, 1] = tf.squeeze(X[X_groups[i][strip_size]])\n",
        "        X_processed[i, strip_size, :, :, 2] = tf.squeeze(X[X_groups[i][strip_size]])\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RalNstSPdPqb"
      },
      "outputs": [],
      "source": [
        "def create_random_set_RGB(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "        #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We want the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = X[X_groups[i][j]]\n",
        "        X_processed[i, strip_size, :, :, :] = X[X_groups[i][strip_size]]\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro3cIeANdPqc"
      },
      "outputs": [],
      "source": [
        "def create_random_data_sets(X, y, Xt, yt, strip_size, RGB, training_size=30000, test_size=2000):\n",
        "    if(RGB):\n",
        "        Xtrain, ytrain = create_random_set_RGB(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.1)\n",
        "        Xtest, ytest = create_random_set_RGB(Xt, yt, strip_size, set_size=test_size)\n",
        "    else:\n",
        "        Xtrain, ytrain = create_random_set(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.1)\n",
        "        Xtest, ytest = create_random_set(Xt, yt, strip_size, set_size=test_size)\n",
        "    \n",
        "    print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "    print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "    print (\"Validation examples classified as 0: \" + str(len(np.where(yval==0)[0])))\n",
        "    print (\"Validation examples classified as 1: \" + str(len(np.where(yval==1)[0])))\n",
        "    print (\"Test examples classified as 0: \" + str(len(np.where(ytest==0)[0])))\n",
        "    print (\"Test examples classified as 1: \" + str(len(np.where(ytest==1)[0])))\n",
        "    \n",
        "    return Xtrain, Xval, Xtest, ytrain, yval, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEeAZhDcdPqd"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, lr=1e-3, batch_size=32, model_save_name=\"best_model\"):\n",
        "\n",
        "    #Define callbacks\n",
        "    #Save the best model\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, model_save_name)\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    \n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "        mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "    #Add early stopping\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose = 0)\n",
        "    #Reduce learning rate on plateau\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=5e-5)\n",
        "    callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "    #Compile and fit the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
        "                  loss='binary_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(Xtrain, ytrain,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=100,\n",
        "                        validation_data=(Xval, yval),\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\"\"\"\n",
        "    \n",
        "    model.load_weights(filepath)\n",
        "    ypredict = model.predict(Xtest)\n",
        "    #ypredict = tf.squeeze(ypredict).numpy()\n",
        "    #print(ypredict)\n",
        "    #ypredict_round = [round(x) for x in ypredict]\n",
        "    score = model.evaluate(Xtest, ytest, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    \n",
        "    #cm = confusion_matrix(ytest, ypredict)\n",
        "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    #disp.plot()\n",
        "    #plt.show()\n",
        "    \n",
        "    return score[1], model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaGWdyVpK-hT"
      },
      "outputs": [],
      "source": [
        "def gray_to_rgb(img):\n",
        "    return np.repeat(img, 3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glr7IxJFdPqe"
      },
      "outputs": [],
      "source": [
        "def see_embeddings(model, X, y, save_name, preprocess_func, pre_model):\n",
        "    embeddings_per_class = 10\n",
        "    classes = 10\n",
        "    # Buscamos 3 imagenes de cada clase\n",
        "    #Creamos una lista de listas donde cada sublista contiene los índices de la imágenes de un número\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(classes)]\n",
        "    \n",
        "    images = np.zeros((classes*embeddings_per_class, X.shape[1], X.shape[2], X.shape[3]))\n",
        "    for i in range(classes):\n",
        "        list_of_indexes = random.choices(list_indices_by_number[i], k=embeddings_per_class)\n",
        "        images[embeddings_per_class*i:(i+1)*embeddings_per_class, :, :, :] = X[list_of_indexes]\n",
        "\n",
        "    if preprocess_func:\n",
        "        prep_images = preprocess_func(images)\n",
        "        prep_X = preprocess_func(X)\n",
        "    else:\n",
        "        prep_images = images\n",
        "        prep_X = X\n",
        "\n",
        "    if pre_model:\n",
        "        prep_images = model.preprocess(prep_images)\n",
        "        prep_X = model.preprocess(prep_X)\n",
        "    \n",
        "    if prep_X.shape[-1] != 3:\n",
        "        prep_images = tf.repeat(prep_images, 3, axis=-1)\n",
        "        prep_X = tf.repeat(prep_X, 3, axis=-1)\n",
        "\n",
        "    encoded_images = model.encoder(prep_images).numpy()\n",
        "    encoded_X = model.encoder(prep_X).numpy()\n",
        "    \n",
        "    plt.figure(figsize=(15, 30))\n",
        "\n",
        "    m = embeddings_per_class\n",
        "    n = classes\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            ax = plt.subplot(m, n, n*i+j+1)\n",
        "            plt.imshow(tf.expand_dims(encoded_images[n*i+j], axis=-1))\n",
        "            plt.title('Class: ' + str(i), fontsize=16)\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "    plt.suptitle('Image embeddings per class', fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    plt.savefig(save_name+ '.png')\n",
        "    plt.show()\n",
        "    \n",
        "    manifold = umap.UMAP().fit(encoded_X)\n",
        "    p = umap.plot.points(manifold, labels=tf.squeeze(y), color_key_cmap='Paired', background='black')\n",
        "    plt.savefig(save_name+'_UMAP'+ '.png')\n",
        "    umap.plot.plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbhvAzQxdPqf"
      },
      "outputs": [],
      "source": [
        "def save_to_db(db_name, column_name, list_to_save):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    df[column_name] = list_to_save\n",
        "    df.to_csv(db_name + '.csv', index=False)\n",
        "\n",
        "def create_db(db_name):\n",
        "    df = pd.DataFrame()\n",
        "    df.to_csv(db_name + '.csv', index=True)\n",
        "\n",
        "def plot_db_columns(db_name, title, xlabel, ylabel, save_name):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    # plot lines\n",
        "    x = [i for i in range(2, 11)]\n",
        "    plt.figure(figsize=(9,7))\n",
        "    \n",
        "    for column in df:\n",
        "        if (column != 'Unnamed: 0'):\n",
        "            plt.plot(x, df[column], label = column)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(axis = 'y', color = 'gray', linestyle = '--', linewidth = 0.5)\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.savefig(save_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_1IsgjzdPqg"
      },
      "outputs": [],
      "source": [
        "def run_model(X, y, Xt, yt, model_class, latent_dim, model_save_name, db_name, column_name, preprocess_func, preprocess_before, num_iterations=3, RGB=True, pre_model=False):\n",
        "    \n",
        "    #Preprocess data\n",
        "    if preprocess_before:\n",
        "        X_processed = preprocess_func(X)\n",
        "        Xt_processed = preprocess_func(Xt)\n",
        "    else:\n",
        "        X_processed = X\n",
        "        Xt_processed = Xt\n",
        "        \n",
        "    accuracy_per_strip_size = []\n",
        "    for strip_size in range(1, 10):\n",
        "        print('-------------------' + str(strip_size) + '-------------------')\n",
        "        channels = strip_size + 1\n",
        "        accuracy_per_iteration = []\n",
        "        for i in range(num_iterations):\n",
        "            print('--------------Iteration ' + str(i+1) + '--------------')\n",
        "            Xtrain, Xval, Xtest, ytrain, yval, ytest = create_random_data_sets(X_processed, y, Xt_processed, yt, strip_size, RGB)\n",
        "            tf.keras.backend.clear_session()\n",
        "            model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3])) \n",
        "            score, model = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=64, model_save_name=model_save_name)\n",
        "            if i == (num_iterations-1):\n",
        "                embedding_file_path = os.path.join('embedding_images', model_save_name + \"_\" + str(channels))\n",
        "                see_embeddings(model, Xt, yt, embedding_file_path, preprocess_func, pre_model)\n",
        "            accuracy_per_iteration.append(score)\n",
        "            del Xtrain\n",
        "            del Xval\n",
        "            del Xtest\n",
        "            del ytrain\n",
        "            del yval\n",
        "            del ytest\n",
        "            gc.collect()\n",
        "        mean_score = np.mean(accuracy_per_iteration)\n",
        "        accuracy_per_strip_size.append(mean_score)\n",
        "    save_to_db(db_name, column_name, accuracy_per_strip_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7JQG6AxbNXA"
      },
      "source": [
        "# Check if the strips are correctly built"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0qeELz0bU0v"
      },
      "outputs": [],
      "source": [
        "strip_size = 5\n",
        "\n",
        "Xtrain, ytrain = create_random_set_RGB(Xtrain_orig/255., ytrain_orig, strip_size, 500)\n",
        "\n",
        "print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "\n",
        "#First show one with expected output 0\n",
        "idx = np.where(ytrain==0)[0][3]\n",
        "f, axarr = plt.subplots(1,strip_size+1)\n",
        "for i in range(strip_size+1):\n",
        "    axarr[i].imshow(Xtrain[idx, i, :, :, :], cmap='gray')\n",
        "\n",
        "#Now one with expected output 1\n",
        "idx = np.where(ytrain==1)[0][0]\n",
        "f, axarr = plt.subplots(1,strip_size+1)\n",
        "for i in range(strip_size+1):\n",
        "    axarr[i].imshow(Xtrain[idx, i, :, :, :], cmap='gray')\n",
        "\n",
        "#Now with black and white images\n",
        "Xtrain_bw = tf.image.rgb_to_grayscale(Xtrain_orig)\n",
        "Xtrain, ytrain = create_random_set(Xtrain_bw/255., ytrain_orig, strip_size, 500)\n",
        "\n",
        "print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "\n",
        "#First show one with expected output 0\n",
        "idx = np.where(ytrain==0)[0][0]\n",
        "f, axarr = plt.subplots(1,strip_size+1)\n",
        "for i in range(strip_size+1):\n",
        "    axarr[i].imshow(Xtrain[idx, i, :, :, :], cmap='gray')\n",
        "\n",
        "#Now one with expected output 1\n",
        "idx = np.where(ytrain==1)[0][0]\n",
        "f, axarr = plt.subplots(1,strip_size+1)\n",
        "for i in range(strip_size+1):\n",
        "    axarr[i].imshow(Xtrain[idx, i, :, :, :], cmap='gray')\n",
        "\n",
        "del Xtrain\n",
        "del Xtrain_bw\n",
        "del ytrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJJ2rzIWdPqh"
      },
      "source": [
        "# Define the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-8rsH4odPqj"
      },
      "outputs": [],
      "source": [
        "def preprocess_identity(images):\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDhq8W3wdPqm"
      },
      "source": [
        "## Modelos con EfficientNetB0 encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrtQ7rPCdPqn"
      },
      "outputs": [],
      "source": [
        "def build_efficientnet_encoder(shape_in, latent_dim):\n",
        "  \n",
        "    inp = layers.Input(shape=shape_in)\n",
        " \n",
        "    # Apply EfficientNet to every image\n",
        "    efficientnet = keras.applications.EfficientNetB0(include_top=False, pooling='avg', weights='imagenet', drop_connect_rate=.5)\n",
        "    x = efficientnet(inp)\n",
        "    \n",
        "    x = layers.Dropout(.8)(x)\n",
        "    x = layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    # Embedding de cada imatge (dim reduced from 2048 to encoding_dim)\n",
        "    x = layers.Dense(latent_dim, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    encoder = keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    return encoder\n",
        "\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "#plot_model(buildEfficientNet((32, 32, 3), 32), to_file='efficientnet_encoder.png', show_shapes=True, show_layer_names=False)\n",
        "#plot_model(tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(32, 32, 3), pooling='avg', drop_connect_rate=0.4), to_file='efficientnet.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61xMsjmKdPqn"
      },
      "outputs": [],
      "source": [
        "class DotEfficientnet(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(DotEfficientnet, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = build_efficientnet_encoder(self.shape_in[1:], self.latent_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "      \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtPMQahtbyFi"
      },
      "outputs": [],
      "source": [
        "class ClassifierEfficientnet(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ClassifierEfficientnet, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = build_efficientnet_encoder(self.shape_in[1:], self.latent_dim)\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "      \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaw1SV1KDZnx"
      },
      "source": [
        "## Models with Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruUeSJ63Dgan"
      },
      "outputs": [],
      "source": [
        "def buildResNet(img_size, latent_dim):\n",
        "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "    base_model = ResNet18(img_size, weights='imagenet', include_top=False, pooling='avg', drop_connect_rate=0.4)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(.3)(x)\n",
        "    predictions = layers.Dense(latent_dim, activation='relu')(x)\n",
        "    \n",
        "    return keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#plot_model(buildResNet((32, 32, 3), 32), to_file='resnet_encoder.png', show_shapes=True, show_layer_names=False)\n",
        "#ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "#plot_model(ResNet18((32, 32, 3), weights='imagenet', include_top=False, pooling='avg', drop_connect_rate=0.4), to_file='resnet.png', show_shapes=True, show_layer_names=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA0VGM-rErqB"
      },
      "outputs": [],
      "source": [
        "class Resnet_Model(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(Resnet_Model, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = buildResNet(self.shape_in, self.latent_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "      \n",
        "        encoded_images_list = []\n",
        "        for i in range(self.channels-1):\n",
        "            channel_i = layers.Lambda(lambda x : x[:,:,:,i:i+(3)])(x)\n",
        "            encoded_images_list.append(self.encoder(channel_i))\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()(encoded_images_list)\n",
        "        else:\n",
        "            max_image = encoded_images_list[0]\n",
        "        \n",
        "        \n",
        "        last_channel = layers.Lambda(lambda x : x[:,:,:,self.channels-1: self.channels+(3)-1])(x)\n",
        "        last_embedding = self.encoder(last_channel)\n",
        "        \n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXDt_LkfdPqo"
      },
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RewT1zIVdPqp"
      },
      "outputs": [],
      "source": [
        "os.mkdir('embedding_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUheD9zsbyFj"
      },
      "outputs": [],
      "source": [
        "create_db('cifar10_efficientnet_encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRLSkwTPdPqz"
      },
      "outputs": [],
      "source": [
        "#Modelos con EfficientNetB0 de encoder y dot product\n",
        "run_model(Xtrain_orig, ytrain_orig, Xtest_orig, ytest_orig, DotEfficientnet, 32, 'embedding_dot_efficient32', 'cifar10_efficientnet_encoder', 'embedding_dot_efficient32', preprocess_identity, True, num_iterations=1, RGB=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlexXc-JbyFk"
      },
      "outputs": [],
      "source": [
        "run_model(Xtrain_orig, ytrain_orig, Xtest_orig, ytest_orig, DotEfficientnet, 10, 'embedding_dot_efficient10', 'cifar10_efficientnet_encoder', 'embedding_dot_efficient10', preprocess_identity, True, num_iterations=1, RGB=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yffO53GObyFk"
      },
      "outputs": [],
      "source": [
        "#Modelos con EfficientNetB0 de encoder y dot product\n",
        "run_model(Xtrain_orig, ytrain_orig, Xtest_orig, ytest_orig, ClassifierEfficientnet, 32, 'embedding_classifier_efficient32', 'cifar10_efficientnet_encoder', 'embedding_classifier_efficient32', preprocess_identity, True, num_iterations=1, RGB=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsXuEv3zbyFk"
      },
      "outputs": [],
      "source": [
        "run_model(Xtrain_orig, ytrain_orig, Xtest_orig, ytest_orig, ClassifierEfficientnet, 10, 'embedding_classifier_efficient10', 'cifar10_efficientnet_encoder', 'embedding_classifier_efficient10', preprocess_identity, True, num_iterations=1, RGB=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rydwWGKdPqz"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59OcBas8dPq0"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('cifar10_efficientnet_encoder', 'Cifar10 model accuracy', 'Strip size', 'Accuracy', 'cifar10_efficientnet_encoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaVm-2VJHDI4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cifar10_rgb_efficientnet.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}