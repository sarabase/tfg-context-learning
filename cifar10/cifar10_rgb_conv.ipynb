{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cifar10 model testing\n",
        "In this notebook we will test if working with grey-scaled images gives better results than working with RGB images. For this, we will try several techniques:\n",
        "- Flatten the three channels **(Flatten)**\n",
        "- Maximum of the three channels **(MaxChannels)**\n",
        "- Use the image with three channels **(Embedding)**\n",
        "- Convolutional layer **(Convolutional)**\n",
        "- Black and white function **(BlackWhite)**"
      ],
      "metadata": {
        "id": "wQKWZtimXb9q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KVDVODsXaWM"
      },
      "source": [
        "# Make the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0hyJqu5XaWP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import shutil\n",
        "import os\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4E_WUtdXaWP"
      },
      "source": [
        "# Import and preprocess Cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3zRVo48XaWQ"
      },
      "outputs": [],
      "source": [
        "(Xtrain_orig, ytrain_orig), (Xtest_orig, ytest_orig) = cifar10.load_data()\n",
        "\n",
        "Xtrain_norm = Xtrain_orig.astype('float32') / 255.\n",
        "Xtest_norm = Xtest_orig.astype('float32') / 255.\n",
        "\n",
        "ytrain_norm = ytrain_orig\n",
        "ytest_norm = ytest_orig\n",
        "\n",
        "print (\"Xtrain shape: \" + str(Xtrain_norm.shape))\n",
        "print (\"ytrain shape: \" + str(ytrain_norm.shape))\n",
        "\n",
        "print (\"Xtest shape: \" + str(Xtest_norm.shape))\n",
        "print (\"ytest shape: \" + str(ytest_norm.shape))\n",
        "\n",
        "del Xtrain_orig\n",
        "del ytrain_orig\n",
        "del Xtest_orig\n",
        "del ytest_orig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thc6KHjcXaWR"
      },
      "source": [
        "# Define some variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHjz5WTlXaWS"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "img_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ-P1HRPXaWS"
      },
      "source": [
        "# Show an image of every class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw_jgsj7XaWT"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(1, 10, figsize=(30, 10))\n",
        "for x in range(10):\n",
        "    idx = np.where(ytrain_norm==x)[0][0]\n",
        "    axarr[x].imshow(Xtrain_norm[idx])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4mb0PXXaWT"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMsDpMv9XaWU"
      },
      "outputs": [],
      "source": [
        "def create_set(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We now want our examples to have the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the expected labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 1])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = tf.expand_dims(X[X_groups[i][j]], axis=-1)\n",
        "        X_processed[i, strip_size, :, :, :] = tf.expand_dims(X[X_groups[i][strip_size]], axis=-1)\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMbCl8r6XaWV"
      },
      "outputs": [],
      "source": [
        "def create_set_RGB(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We now want our examples to have the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the expected labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = X[X_groups[i][j]]\n",
        "        X_processed[i, strip_size, :, :, :] = X[X_groups[i][strip_size]]\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzoBcwGVXaWW"
      },
      "outputs": [],
      "source": [
        "def create_data_sets(X, y, Xt, yt, strip_size, RGB, training_size=20000, test_size=4000):\n",
        "    if(RGB):\n",
        "        Xtrain, ytrain = create_set_RGB(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
        "        Xtest, ytest = create_set_RGB(Xt, yt, strip_size, set_size=test_size)\n",
        "    else:\n",
        "        #Transform the images to black and white\n",
        "        Xtrain, ytrain = create_set(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
        "        Xtest, ytest = create_set(Xt, yt, strip_size, set_size=test_size)\n",
        "    \n",
        "    \"\"\"print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "    print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "    print (\"Validation examples classified as 0: \" + str(len(np.where(yval==0)[0])))\n",
        "    print (\"Validation examples classified as 1: \" + str(len(np.where(yval==1)[0])))\n",
        "    print (\"Test examples classified as 0: \" + str(len(np.where(ytest==0)[0])))\n",
        "    print (\"Test examples classified as 1: \" + str(len(np.where(ytest==1)[0])))\"\"\"\n",
        "    \n",
        "    return Xtrain, Xval, Xtest, ytrain, yval, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5OiPHf6XaWW"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, lr=1e-3, batch_size=32, model_save_name=\"best_model\"):\n",
        "    \n",
        "    #Define callbacks\n",
        "    #Save the best model\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, model_save_name)\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "        mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "    #Add early stopping\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "    #Reduce learning rate on plateau\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "    callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "    \n",
        "    #Compile and fit the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(Xtrain, ytrain,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=80,\n",
        "                        validation_data=(Xval, yval),\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\"\"\"\n",
        "    \n",
        "    model.load_weights(filepath)\n",
        "    ypredict = model.predict(Xtest)\n",
        "    #ypredict = tf.squeeze(ypredict).numpy()\n",
        "    #print(ypredict)\n",
        "    #ypredict_round = [round(x) for x in ypredict]\n",
        "    score = model.evaluate(Xtest, ytest, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    \n",
        "    #cm = confusion_matrix(ytest, ypredict)\n",
        "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    #disp.plot()\n",
        "    #plt.show()\n",
        "    \n",
        "    return score[1], model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSqvimCCXaWX"
      },
      "outputs": [],
      "source": [
        "def save_to_db(db_name, column_name, list_to_save):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    df[column_name] = list_to_save\n",
        "    df.to_csv(db_name + '.csv', index=False)\n",
        "\n",
        "def create_db(db_name):\n",
        "    df = pd.DataFrame()\n",
        "    df.to_csv(db_name + '.csv', index=True)\n",
        "\n",
        "def plot_db_columns(db_name, title, xlabel, ylabel, save_name):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    # plot lines\n",
        "    x = [i for i in range(2, 11)]\n",
        "    plt.figure(figsize=(9,7))\n",
        "    \n",
        "    for column in df:\n",
        "        if (column != 'Unnamed: 0'):\n",
        "            plt.plot(x, df[column], label = column)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(axis = 'y', color = 'gray', linestyle = '--', linewidth = 0.5)\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.savefig(save_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HomV9-xXaWX"
      },
      "outputs": [],
      "source": [
        "def run_model(X, y, Xt, yt, model_class, latent_dim, model_save_name, db_name, column_name, preprocess_func, preprocess_before, num_iterations=3, RGB=True, pre_model=None, lr=1e-3):\n",
        "    \n",
        "    #Preprocess data\n",
        "    if preprocess_before:\n",
        "        X_processed = preprocess_func(X)\n",
        "        Xt_processed = preprocess_func(Xt)\n",
        "    else:\n",
        "        X_processed = X\n",
        "        Xt_processed = Xt\n",
        "        \n",
        "    accuracy_per_strip_size = []\n",
        "    for strip_size in range(1, 10):\n",
        "        print('-------------------' + str(strip_size) + '-------------------')\n",
        "        channels = strip_size + 1\n",
        "        accuracy_per_iteration = []\n",
        "        for i in range(num_iterations):\n",
        "            print('--------------Iteration ' + str(i+1) + '--------------')\n",
        "            Xtrain, Xval, Xtest, ytrain, yval, ytest = create_data_sets(X_processed, y, Xt_processed, yt, strip_size, RGB=RGB)\n",
        "            tf.keras.backend.clear_session()\n",
        "            if pre_model:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3]), pre_model)\n",
        "            else:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3])) \n",
        "            score, model = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, lr=lr, batch_size=32, model_save_name=model_save_name)\n",
        "            accuracy_per_iteration.append(score)\n",
        "            del Xtrain\n",
        "            del Xval\n",
        "            del Xtest\n",
        "            del ytrain\n",
        "            del yval\n",
        "            del ytest\n",
        "            del model\n",
        "        accuracy_per_strip_size.append(np.mean(accuracy_per_iteration))\n",
        "    save_to_db(db_name, column_name, accuracy_per_strip_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkpGaM3JXaWY"
      },
      "source": [
        "# Creamos el csv donde guardaremos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qvLEpzuXaWY"
      },
      "outputs": [],
      "source": [
        "create_db('cifar10_conv_encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00fz3SHgXaWY"
      },
      "source": [
        "# Definimos los modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHTNiO2wXaWZ"
      },
      "source": [
        "We will test the models with two different encoder blocks:\n",
        "- If the model is named ---2, then it will be using the same encoder we used with the Fashion-MNIST dataset. \n",
        "- If the model is named ---3, then it will be using a new encoder better prepared for the Cifar10 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e-afrj9XaWZ"
      },
      "source": [
        "## Models with encoder 2\n",
        "### With the dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWb1fdwKXaWZ"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderDot2(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderDot2, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5mHDeOuXaWZ"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderDot2Pre(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderDot2Pre, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=[self.shape_in[1], self.shape_in[2], 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPool2D(pool_size=(2,2)),\n",
        "            \n",
        "            layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.BatchNormalization(),\n",
        "            \n",
        "            layers.Flatten(),\n",
        "            \n",
        "            layers.Dense(units=latent_dim)\n",
        "            \n",
        "        ])\n",
        "        \n",
        "        self.pre_encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(1, (1,1), padding='same', input_shape=self.shape_in[1:])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        preencoded_images = layers.TimeDistributed(self.pre_encoder)(x)\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(preencoded_images)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qce9XO9XaWa"
      },
      "source": [
        "## Models with encoder 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXMWhAOZXaWa"
      },
      "source": [
        "### With the dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLNDp8AuXaWa"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderDot3(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderDot3, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = keras.models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.4),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(self.latent_dim, activation='relu', kernel_initializer='he_uniform'),\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGKdT0ewXaWa"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderDot3Pre(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderDot3Pre, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = keras.models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=[self.shape_in[1], self.shape_in[2], 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.4),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(self.latent_dim, activation='relu', kernel_initializer='he_uniform'),\n",
        "        ])\n",
        "\n",
        "        self.pre_encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(1, (1,1), padding='same', input_shape=self.shape_in[1:])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        preencoded_images = layers.TimeDistributed(self.pre_encoder)(x)\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(preencoded_images)\n",
        "        \n",
        "        if(self.channels > 2):\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "            \n",
        "        last_embedding = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        y_predict = layers.Dot(axes=1, normalize=True)([max_image, last_embedding])\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJCpkkfWXaWb"
      },
      "source": [
        "### With the dense classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g6zUaXkXaWb"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderClassifier3(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderClassifier3, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = keras.models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=self.shape_in[1:]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.4),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(self.latent_dim, activation='relu', kernel_initializer='he_uniform'),\n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(x)\n",
        "        if self.channels > 2:\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc-2e3vFXaWb"
      },
      "outputs": [],
      "source": [
        "class ConvEncoderClassifier3Pre(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ConvEncoderClassifier3Pre, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = keras.models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=[self.shape_in[1], self.shape_in[2], 1]),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.2),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.4),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(self.latent_dim, kernel_initializer='he_uniform'),\n",
        "        ])\n",
        "        \n",
        "        self.classifier = tf.keras.Sequential([\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(512, activation='relu'),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        self.pre_encoder = tf.keras.Sequential([\n",
        "            layers.Conv2D(1, (1,1), padding='same', input_shape=self.shape_in[1:])\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        \n",
        "        preencoded_images = layers.TimeDistributed(self.pre_encoder)(x)\n",
        "        encoded_images = layers.TimeDistributed(self.encoder)(preencoded_images)\n",
        "        \n",
        "        if self.channels > 2:\n",
        "            max_image = layers.Maximum()([layers.Lambda(lambda x : x[:,i,:])(encoded_images) for i in range(self.channels-1)])\n",
        "        else:\n",
        "            max_image = layers.Lambda(lambda x : x[:,0,:])(encoded_images)\n",
        "\n",
        "        target_image = layers.Lambda(lambda x : x[:,-1,:])(encoded_images)\n",
        "        stacked_image = tf.stack([max_image, target_image], axis=-1)\n",
        "        y_predict = self.classifier(stacked_image)\n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-gJz4oXaWc"
      },
      "source": [
        "## Define the preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpQEt4LFXaWc"
      },
      "outputs": [],
      "source": [
        "def preprocess_flatten(images):\n",
        "    flat_images = layers.Flatten()(images)\n",
        "    reshape_images = layers.Reshape((images.shape[1], images.shape[2]*images.shape[3]))(flat_images)\n",
        "    return reshape_images\n",
        "\n",
        "\n",
        "def preprocess_maxchannels(images):\n",
        "    max_images = layers.Maximum()([images[:, :, :, 0], images[:, :, :, 1], images[:, :, :, 2]])\n",
        "    return max_images\n",
        "\n",
        "\n",
        "def preprocess_identity(images):\n",
        "    return images\n",
        "\n",
        "\n",
        "def preprocess_black_and_white(images):\n",
        "    b_w_images = tf.image.rgb_to_grayscale(images)\n",
        "    return tf.squeeze(b_w_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZNYnEgYXaWc"
      },
      "source": [
        "# Train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "g3TrKMNAXaWc"
      },
      "outputs": [],
      "source": [
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot2, 32, 'flatten_dot2', 'cifar10_conv_encoder', 'flatten_dot2', preprocess_flatten, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot2, 32, 'max_dot2', 'cifar10_conv_encoder', 'max_dot2', preprocess_maxchannels, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot2, 32, 'embedding_dot2', 'cifar10_conv_encoder', 'embedding_dot2', preprocess_identity, True, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot2, 32, 'black_white_dot2', 'cifar10_conv_encoder', 'black_white_dot2', preprocess_black_and_white, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot2Pre, 32, 'conv_dot2', 'cifar10_conv_encoder', 'conv_dot2', None, False, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e7DTINFXaWc"
      },
      "outputs": [],
      "source": [
        "#Modelos con encoder Cifar10 y dot product\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot3, 32, 'embedding_dot3', 'cifar10_conv_encoder', 'embedding_dot3', preprocess_identity, True, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot3, 32, 'black_white_dot3', 'cifar10_conv_encoder', 'black_white_dot3', preprocess_black_and_white, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot3Pre, 32, 'conv_dot3', 'cifar10_conv_encoder', 'conv_dot3', None, False, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot3, 32, 'flatten_dot3', 'cifar10_conv_encoder', 'flatten_dot3', preprocess_flatten, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderDot3, 32, 'max_dot3', 'cifar10_conv_encoder', 'max_dot3', preprocess_maxchannels, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH6NabXbXaWd"
      },
      "outputs": [],
      "source": [
        "#Modelos con encoder Cifar10 y classifier\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderClassifier3, 32, 'embedding_classifier3', 'cifar10_conv_encoder', 'embedding_classifier3', preprocess_identity, True, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderClassifier3, 32, 'black_white_classifier3', 'cifar10_conv_encoder', 'black_white_classifier3', preprocess_black_and_white, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderClassifier3Pre, 32, 'conv_classifier3', 'cifar10_conv_encoder', 'conv_classifier3', None, False, num_iterations=1, RGB=True, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderClassifier3, 32, 'flatten_classifier3', 'cifar10_conv_encoder', 'flatten_classifier3', preprocess_flatten, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "run_model(Xtrain_norm, ytrain_norm, Xtest_norm, ytest_norm, ConvEncoderClassifier3, 32, 'max_classifier3', 'cifar10_conv_encoder', 'max_dot3', preprocess_maxchannels, True, num_iterations=1, RGB=False, pre_model=None, lr=1e-3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoLauriJXaWd"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scXOmy6-XaWd"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('cifar10_conv_encoder', 'Cifar10 model accuracy', 'Strip size', 'Accuracy', 'cifar10_conv_encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDOXg-XQXaWd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "cifar10-rgb-conv.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}