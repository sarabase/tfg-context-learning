{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BptblzjIC2"
      },
      "source": [
        "# Cifar10 model testing\n",
        "In this notebook we will try a different approach for the context learning methodology. Instead of using a convolutional architecture, we will use a recurrent neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdH2kgk5jIC4"
      },
      "source": [
        "## Make the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E71rx94z6wvr"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git\n",
        "!pip install umap-learn[plot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAzNqAEtjIC7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from classification_models.tfkeras import Classifiers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import shutil\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import umap.umap_ as umap\n",
        "import umap.plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roFvIgojjIC8"
      },
      "source": [
        "## Import and preprocess the Cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apv5xlz_jIC9"
      },
      "outputs": [],
      "source": [
        "(Xtrain_orig, ytrain_orig), (Xtest_orig, ytest_orig) = cifar10.load_data()\n",
        "\n",
        "#We do not normalize the data as it it part of the training process with EfficientNet\n",
        "Xtrain = Xtrain_orig.astype('float32')\n",
        "Xtest = Xtest_orig.astype('float32')\n",
        "\n",
        "ytrain = ytrain_orig\n",
        "ytest = ytest_orig\n",
        "\n",
        "print (\"Xtrain shape: \" + str(Xtrain.shape))\n",
        "print (\"ytrain shape: \" + str(ytrain.shape))\n",
        "\n",
        "print (\"Xtest shape: \" + str(Xtest.shape))\n",
        "print (\"ytest shape: \" + str(ytest.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY7Lv2w3jIDB"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBKAkamXjIDB"
      },
      "outputs": [],
      "source": [
        "def create_random_set(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We want the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, 0] = tf.expand_dims(tf.squeeze(X[X_groups[i][j]]), axis=0)\n",
        "            X_processed[i, j:j+1, :, :, 1] = tf.expand_dims(tf.squeeze(X[X_groups[i][j]]), axis=0)\n",
        "            X_processed[i, j:j+1, :, :, 2] = tf.expand_dims(tf.squeeze(X[X_groups[i][j]]), axis=0)\n",
        "        X_processed[i, strip_size, :, :, 0] = tf.expand_dims(tf.squeeze(X[X_groups[i][strip_size]]), axis=0)\n",
        "        X_processed[i, strip_size, :, :, 1] = tf.expand_dims(tf.squeeze(X[X_groups[i][strip_size]]), axis=0)\n",
        "        X_processed[i, strip_size, :, :, 2] = tf.expand_dims(tf.squeeze(X[X_groups[i][strip_size]]), axis=0)\n",
        "        y_processed[i] = y_label[i] \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufl-TaG0jIDD"
      },
      "outputs": [],
      "source": [
        "def create_random_set_RGB(X, y, strip_size=4, set_size=60000):\n",
        "    \n",
        "    #Create a list of lists where every sublist contains the indexes of the images belonging to a class\n",
        "    list_indices_by_number = [np.where(y == i)[0] for i in range(10)]\n",
        "    \n",
        "    #Create the strips of images\n",
        "    X_groups = []\n",
        "    number_groups = []\n",
        "    y_label = []\n",
        "    \n",
        "    for i in range(set_size): #Create as many images as strip_size\n",
        "        group_i = []\n",
        "        numbers_i = []\n",
        "        while len(group_i) < strip_size: #While the strip is shorter that the size wanted\n",
        "            #Choose a random index\n",
        "            image_idx = random.randint(0, len(X)-1)\n",
        "            numbers_i.append(y[image_idx][0])\n",
        "            group_i.append(image_idx)\n",
        "        #When the strip is full, add the target image. Use random to obtain a balanced set.\n",
        "        repeated = np.random.choice([0, 1], p=[0.50, 0.50])\n",
        "        if repeated:\n",
        "            #Look for a number whose class is already contained in the strip.\n",
        "            random_idx = random.randint(0, len(numbers_i)-1)\n",
        "            number = numbers_i[random_idx]\n",
        "            numbers_i.append(number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[number])-1)\n",
        "            group_i.append(list_indices_by_number[number][image_idx])\n",
        "            y_label.append(1)\n",
        "        else:\n",
        "            #Add a number that is not aready in the strip\n",
        "            possible_numbers = [x for x in range(10) if x not in numbers_i]\n",
        "            random_number = random.choice(possible_numbers)\n",
        "            numbers_i.append(random_number)\n",
        "            #Choose a random image representing the chosen class\n",
        "            image_idx = random.randint(0, len(list_indices_by_number[random_number])-1)\n",
        "            group_i.append(list_indices_by_number[random_number][image_idx])\n",
        "            y_label.append(0)\n",
        "        X_groups.append(group_i)\n",
        "        number_groups.append(numbers_i)\n",
        "    \n",
        "    #We want the following shape: (N, strip_size+1, X_train[1], X_train[2], 3)\n",
        "    #And create the labels\n",
        "    N = len(X_groups)\n",
        "    img_size1 = X.shape[1]\n",
        "    img_size2 = X.shape[2]\n",
        "    X_processed= np.zeros([N, strip_size+1, img_size1, img_size2, 3])\n",
        "    y_processed = np.zeros([N])\n",
        "    for i in range(N):\n",
        "        numbers_i = list(dict.fromkeys(number_groups[i]))\n",
        "        for j in range(strip_size):\n",
        "            X_processed[i, j:j+1, :, :, :] = X[X_groups[i][j]]\n",
        "        X_processed[i, strip_size, :, :, :] = X[X_groups[i][strip_size]]\n",
        "        y_processed[i] = y_label[i]\n",
        "        \n",
        "        \n",
        "    return X_processed, y_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l-SH0qJjIDE"
      },
      "outputs": [],
      "source": [
        "def create_random_data_sets(X, y, Xt, yt, strip_size, RGB, training_size=30000, test_size=8000):\n",
        "    if(RGB):\n",
        "        Xtrain, ytrain = create_random_set_RGB(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.1)\n",
        "        Xtest, ytest = create_random_set_RGB(Xt, yt, strip_size, set_size=test_size)\n",
        "    else:\n",
        "        #Transform the images to black and white\n",
        "        Xtrain, ytrain = create_random_set(X, y, strip_size, set_size=training_size)\n",
        "        Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.1)\n",
        "        Xtest, ytest = create_random_set(Xt, yt, strip_size, set_size=test_size)\n",
        "    \n",
        "    print (\"Training examples classified as 0: \" + str(len(np.where(ytrain==0)[0])))\n",
        "    print (\"Training examples classified as 1: \" + str(len(np.where(ytrain==1)[0])))\n",
        "    print (\"Validation examples classified as 0: \" + str(len(np.where(yval==0)[0])))\n",
        "    print (\"Validation examples classified as 1: \" + str(len(np.where(yval==1)[0])))\n",
        "    print (\"Test examples classified as 0: \" + str(len(np.where(ytest==0)[0])))\n",
        "    print (\"Test examples classified as 1: \" + str(len(np.where(ytest==1)[0])))\n",
        "    \n",
        "    return Xtrain, Xval, Xtest, ytrain, yval, ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGctqwjijIDE"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=32, model_save_name=\"best_model\"):\n",
        "\n",
        "    #Define callbacks\n",
        "    #Save the best model\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, model_save_name)\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    \n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "        mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "    #Add early stopping\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "    #Reduce learning rate on plateau\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.65, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "    callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "    #Compile and fit the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(Xtrain, ytrain,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=100,\n",
        "                        validation_data=(Xval, yval),\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1)\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\"\"\"\n",
        "    \n",
        "    model.load_weights(filepath)\n",
        "    ypredict = model.predict(Xtest)\n",
        "    #ypredict = tf.squeeze(ypredict).numpy()\n",
        "    #print(ypredict)\n",
        "    #ypredict_round = [round(x) for x in ypredict]\n",
        "    score = model.evaluate(Xtest, ytest, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    \n",
        "    #cm = confusion_matrix(ytest, ypredict)\n",
        "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    #disp.plot()\n",
        "    #plt.show()\n",
        "    \n",
        "    return score[1], model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJLdDa_6jIDF"
      },
      "outputs": [],
      "source": [
        "def see_embeddings(model, X, y, save_name, preprocess_func, pre_model=None):\n",
        "    embeddings_per_class = 10\n",
        "    classes = 10\n",
        "    # Buscamos 3 imagenes de cada clase\n",
        "    #Creamos una lista de listas donde cada sublista contiene los índices de la imágenes de un número\n",
        "    \"\"\"list_indices_by_number = [np.where(y == i)[0] for i in range(classes)]\n",
        "    \n",
        "    images = np.zeros((classes*embeddings_per_class, X.shape[1], X.shape[2], X.shape[3]))\n",
        "    for i in range(classes):\n",
        "        list_of_indexes = random.choices(list_indices_by_number[i], k=embeddings_per_class)\n",
        "        images[embeddings_per_class*i:(i+1)*embeddings_per_class, :, :, :] = X[list_of_indexes]\n",
        "\"\"\"\n",
        "    if preprocess_func:\n",
        "        #prep_images = preprocess_func(images)\n",
        "        prep_X = preprocess_func(X)\n",
        "    else:\n",
        "        #prep_images = images\n",
        "        prep_X = X\n",
        "\n",
        "    if pre_model:\n",
        "        #prep_images = model.preprocess(prep_images)\n",
        "        prep_X = model.preprocess(prep_X)\n",
        "    \n",
        "    if prep_X.shape[-1] != 3:\n",
        "        #images_3d = np.zeros((classes*embeddings_per_class, prep_images.shape[1], prep_images.shape[2], 3))\n",
        "        #for i in range(classes*embeddings_per_class):\n",
        "            #images_3d[i, :, : , :] = np.repeat(prep_images[i, :, :, :], 3, 2)\n",
        "        #prep_images = images_3d\n",
        "        prep_X = tf.repeat(prep_X, 3, axis=-1)\n",
        "\n",
        "    #encoded_images = model.encoder(prep_images).numpy()\n",
        "    encoded_X = model.encoder(prep_X).numpy()\n",
        "    \n",
        "    \"\"\"plt.figure(figsize=(15, 30))\n",
        "\n",
        "    m = embeddings_per_class\n",
        "    n = classes\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            ax = plt.subplot(m, n, n*i+j+1)\n",
        "            plt.imshow(tf.expand_dims(encoded_images[n*i+j], axis=-1))\n",
        "            plt.title('Class: ' + str(i), fontsize=16)\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "    plt.suptitle('Image embeddings per class', fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    plt.savefig(save_name+ '.png')\n",
        "    plt.show()\"\"\"\n",
        "    \n",
        "    manifold = umap.UMAP().fit(encoded_X)\n",
        "    p = umap.plot.points(manifold, labels=tf.squeeze(y), color_key_cmap='Paired', background='black')\n",
        "    plt.savefig(save_name+'_UMAP'+ '.png')\n",
        "    umap.plot.plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ublu0jYZjIDG"
      },
      "outputs": [],
      "source": [
        "def save_to_db(db_name, column_name, list_to_save):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    df[column_name] = list_to_save\n",
        "    df.to_csv(db_name + '.csv', index=False)\n",
        "\n",
        "def create_db(db_name):\n",
        "    df = pd.DataFrame()\n",
        "    df.to_csv(db_name + '.csv', index=True)\n",
        "\n",
        "def plot_db_columns(db_name, title, xlabel, ylabel, save_name):\n",
        "    df = pd.read_csv(db_name + '.csv')\n",
        "    # plot lines\n",
        "    x = [i for i in range(1, 10)]\n",
        "    plt.figure(figsize=(9,7))\n",
        "    \n",
        "    for column in df:\n",
        "        if (column != 'Unnamed: 0'):\n",
        "            plt.plot(x, df[column], label = column)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend()\n",
        "    plt.grid(axis = 'y', color = 'gray', linestyle = '--', linewidth = 0.5)\n",
        "    plt.tick_params(labelsize=14)\n",
        "    plt.savefig(save_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GggOCtAojIDG"
      },
      "outputs": [],
      "source": [
        "def run_model(X, y, Xt, yt, model_class, latent_dim, model_save_name, db_name, column_name, preprocess_func, preprocess_before, num_iterations=3, RGB=True, pre_model=None):\n",
        "    \n",
        "    #Preprocess data\n",
        "    if preprocess_before:\n",
        "        X_processed = preprocess_func(X)\n",
        "        Xt_processed = preprocess_func(Xt)\n",
        "    else:\n",
        "        X_processed = X\n",
        "        Xt_processed = Xt\n",
        "        \n",
        "    accuracy_per_strip_size = []\n",
        "    for strip_size in range(1, 10):\n",
        "        print('-------------------' + str(strip_size) + '-------------------')\n",
        "        channels = strip_size + 1\n",
        "        accuracy_per_iteration = []\n",
        "        for i in range(num_iterations):\n",
        "            print('--------------Iteration ' + str(i+1) + '--------------')\n",
        "            Xtrain, Xval, Xtest, ytrain, yval, ytest = create_random_data_sets(X_processed, y, Xt_processed, yt, strip_size, RGB)\n",
        "            tf.keras.backend.clear_session()\n",
        "            if pre_model:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3]), pre_model)\n",
        "            else:\n",
        "                model = model_class(latent_dim, channels, (None, Xtrain[0].shape[1], Xtrain[0].shape[2], Xtrain[0].shape[3])) \n",
        "            score, model = train_model(model, Xtrain, ytrain, Xval, yval, Xtest, ytest, batch_size=64, model_save_name=model_save_name)\n",
        "            if i == (num_iterations-1):\n",
        "                embedding_file_path = os.path.join('embedding_images', model_save_name + \"_\" + str(channels))\n",
        "                see_embeddings(model, Xt, yt, embedding_file_path, preprocess_func)\n",
        "            accuracy_per_iteration.append(score)\n",
        "            del Xtrain\n",
        "            del Xval\n",
        "            del Xtest\n",
        "            del ytrain\n",
        "            del yval\n",
        "            del ytest\n",
        "            gc.collect()\n",
        "        mean_score = np.mean(accuracy_per_iteration)\n",
        "        accuracy_per_strip_size.append(mean_score)\n",
        "    save_to_db(db_name, column_name, accuracy_per_strip_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrnBV2XMjIDH"
      },
      "source": [
        "## Define the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwcl3ghzjIDJ"
      },
      "source": [
        "## Functions to build the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH3gk6wfmNwR"
      },
      "outputs": [],
      "source": [
        "def build_efficientnet_encoder(shape_in, latent_dim):\n",
        "  \n",
        "    inp = layers.Input(shape=shape_in)\n",
        " \n",
        "    # Apply EfficientNet to every image\n",
        "    efficientnet = keras.applications.EfficientNetB0(include_top=False, pooling='avg', weights='imagenet', drop_connect_rate=.5)\n",
        "    x = efficientnet(inp)\n",
        "    \n",
        "    x = layers.Dropout(.8)(x)\n",
        "    x = layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    # Embedding de cada imatge (dim reduced from 2048 to encoding_dim)\n",
        "    x = layers.Dense(latent_dim, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    encoder = keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctBiiUnUmxB0"
      },
      "outputs": [],
      "source": [
        "def build_pretrained_efficientnet_encoder(shape_in, latent_dim):\n",
        "\n",
        "    inp = layers.Input(shape=shape_in)\n",
        " \n",
        "    # Apply EfficientNet to every image\n",
        "    efficientnet = keras.applications.EfficientNetB0(include_top=False, pooling='avg', weights='imagenet', drop_connect_rate=.5)\n",
        "    x = efficientnet(inp)\n",
        "    \n",
        "    x = layers.Dropout(.8)(x)\n",
        "    x = layers.Dense(2048, activation='relu')(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    # Embedding de cada imatge (dim reduced from 2048 to encoding_dim)\n",
        "    x = layers.Dense(latent_dim, activation='relu')(x)\n",
        "    encoder = keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, 'pretrained_efficientnet' + str(latent_dim))\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    encoder.load_weights(filepath)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR9S2TPPcezq"
      },
      "outputs": [],
      "source": [
        "def build_resnet_encoder(shape_in, latent_dim):\n",
        "\n",
        "    inp = layers.Input(shape=shape_in)\n",
        " \n",
        "    # Apply EfficientNet to every image\n",
        "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "    resnet = ResNet18(shape_in, weights='imagenet', include_top=False, pooling='avg')\n",
        "    x = resnet(inp)\n",
        "    \n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(.8)(x)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    # Embedding de cada imatge (dim reduced from 2048 to encoding_dim)\n",
        "    x = layers.Dense(latent_dim, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    encoder = keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUfgLgexd2C6"
      },
      "outputs": [],
      "source": [
        "def build_pretrained_resnet_encoder(shape_in, latent_dim):\n",
        "  \n",
        "    inp = layers.Input(shape=shape_in)\n",
        " \n",
        "    # Apply EfficientNet to every image\n",
        "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "    resnet = ResNet18(shape_in, weights='imagenet', include_top=False, pooling='avg')\n",
        "    x = resnet(inp)\n",
        "    \n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(.8)(x)\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    # Embedding de cada imatge (dim reduced from 2048 to encoding_dim)\n",
        "    x = layers.Dense(latent_dim, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(0.01))(x)\n",
        "    encoder = keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    dirname = os.getcwd()\n",
        "    filepath = os.path.join(dirname, 'pretrained_resnet' + str(latent_dim))\n",
        "    filepath = os.path.join(filepath, 'model')\n",
        "    encoder.load_weights(filepath)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHdMQFN2QNfE"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model(shape_in, encoder):\n",
        "    inp = layers.Input(shape=shape_in)\n",
        "\n",
        "    encoded_out = layers.TimeDistributed(encoder)(inp)\n",
        "\n",
        "    gru1 = layers.GRU(256, return_sequences=True, recurrent_dropout=.7)(encoded_out)\n",
        "    gru2 = layers.GRU(128, return_sequences=True, recurrent_dropout=.7)(gru1)\n",
        "    gru3 = layers.GRU(64, return_sequences=False, recurrent_dropout=.7)(gru2)\n",
        "\n",
        "    dense3 = layers.Dense(128, activation='relu')(gru3)\n",
        "    dense4 = layers.Dense(64, activation='relu')(dense3)\n",
        "    drop3 = layers.Dropout(.5)(dense4)\n",
        "\n",
        "    dense4 = layers.Dense(64, activation='relu')(drop3)\n",
        "    out = layers.Dense(1, activation='sigmoid')(dense4)\n",
        "\n",
        "    model = keras.Model(inputs=inp, outputs=out)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCFRFpRvupEi"
      },
      "source": [
        "## Build the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uc2WX8XjIDJ"
      },
      "outputs": [],
      "source": [
        "class EfficientNetModel(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(EfficientNetModel, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = build_pretrained_efficientnet_encoder(self.shape_in[1:], self.latent_dim)\n",
        "\n",
        "        self.model = build_lstm_model(self.shape_in, self.encoder)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        y_predict = self.model(x)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjKYoejB6s6v"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(keras.Model):\n",
        "    def __init__(self, latent_dim, channels, shape_in):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.channels = channels\n",
        "        self.shape_in = shape_in\n",
        "        \n",
        "        self.encoder = build_pretrained_resnet_encoder(self.shape_in[1:], self.latent_dim)\n",
        "\n",
        "        self.model = build_lstm_model(self.shape_in, self.encoder)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        y_predict = self.model(x)\n",
        "        \n",
        "        return y_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66a074XjmEU5"
      },
      "source": [
        "## First train EfficientNetB0 as classifier\n",
        "We want to first train the EfficientNetB0 as a classifier so we can then load the weights to the encoder in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDoh0FyRh1Sd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_data(X, Y):\n",
        "    X_p = keras.applications.efficientnet.preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 32)\n",
        "    return X, Y_p\n",
        "\n",
        "efficientnet_model = build_efficientnet_encoder((32, 32, 3), 32)\n",
        "\n",
        "X, y = preprocess_data(Xtrain, ytrain)\n",
        "X, Xv, y, yv = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(X)\n",
        "\n",
        "#Define callbacks\n",
        "#Save the best model\n",
        "dirname = os.getcwd()\n",
        "filepath = os.path.join(dirname, 'pretrained_efficientnet32')\n",
        "filepath = os.path.join(filepath, 'model')\n",
        "\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "    mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "#Add early stopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "#Reduce learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.65, patience=5, min_lr=0.000001, verbose=1)\n",
        "\n",
        "callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "#Compile and fit the model\n",
        "efficientnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = efficientnet_model.fit_generator(datagen.flow(X, y, batch_size=128), steps_per_epoch = len(X) / 128, epochs=200, validation_data=(Xv, yv), callbacks=callbacks)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "efficientnet_model.load_weights(filepath)\n",
        "\n",
        "Xt, yt = preprocess_data(Xtest, ytest)\n",
        "\n",
        "ypredict = efficientnet_model.predict(Xt)\n",
        "\n",
        "#ypredict = tf.squeeze(ypredict).numpy()\n",
        "#print(ypredict)\n",
        "#ypredict_round = [round(x) for x in ypredict]\n",
        "score = efficientnet_model.evaluate(Xt, yt, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHkv7V0AmMQm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_data(X, Y):\n",
        "    X_p = keras.applications.efficientnet.preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 10)\n",
        "    return X, Y_p\n",
        "\n",
        "efficientnet_model = build_efficientnet_encoder((32, 32, 3), 10)\n",
        "\n",
        "X, y = preprocess_data(Xtrain, ytrain)\n",
        "X, Xv, y, yv = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(X)\n",
        "\n",
        "#Define callbacks\n",
        "#Save the best model\n",
        "dirname = os.getcwd()\n",
        "filepath = os.path.join(dirname, 'pretrained_efficientnet10')\n",
        "filepath = os.path.join(filepath, 'model')\n",
        "\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "    mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "#Add early stopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "#Reduce learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.65, patience=5, min_lr=0.000001, verbose=1)\n",
        "\n",
        "callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "#Compile and fit the model\n",
        "efficientnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = efficientnet_model.fit_generator(datagen.flow(X, y, batch_size=128), steps_per_epoch = len(X) / 128, epochs=200, validation_data=(Xv, yv), callbacks=callbacks)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "efficientnet_model.load_weights(filepath)\n",
        "\n",
        "Xt, yt = preprocess_data(Xtest, ytest)\n",
        "\n",
        "ypredict = efficientnet_model.predict(Xt)\n",
        "\n",
        "#ypredict = tf.squeeze(ypredict).numpy()\n",
        "#print(ypredict)\n",
        "#ypredict_round = [round(x) for x in ypredict]\n",
        "score = efficientnet_model.evaluate(Xt, yt, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z1ZBhYgJ2Tq"
      },
      "source": [
        "## First train Resnet18 as classifier\n",
        "We want to first train the Resnet18 as a classifier so we can then load the weights to the encoder in the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#Creamos el modelo\n",
        "def preprocess_data(X, Y):\n",
        "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "    X_p = preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 32)\n",
        "    return X, Y_p\n",
        "\n",
        "resnet_model = build_resnet_encoder((32, 32, 3), 32)\n",
        "\n",
        "X, y = preprocess_data(Xtrain, ytrain)\n",
        "X, Xv, y, yv = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(X)\n",
        "\n",
        "#Define callbacks\n",
        "#Save the best model\n",
        "dirname = os.getcwd()\n",
        "filepath = os.path.join(dirname, 'pretrained_resnet32')\n",
        "filepath = os.path.join(filepath, 'model')\n",
        "\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "    mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "#Add early stopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "#Reduce learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.65, patience=5, min_lr=0.000001, verbose=1)\n",
        "\n",
        "callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "#Compile and fit the model\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = resnet_model.fit_generator(datagen.flow(X, y, batch_size=128), steps_per_epoch = len(X) / 128, epochs=200, validation_data=(Xv, yv), callbacks=callbacks)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "resnet_model.load_weights(filepath)\n",
        "\n",
        "Xt, yt = preprocess_data(Xtest, ytest)\n",
        "\n",
        "ypredict = resnet_model.predict(Xt)\n",
        "#ypredict = tf.squeeze(ypredict).numpy()\n",
        "#print(ypredict)\n",
        "#ypredict_round = [round(x) for x in ypredict]\n",
        "score = resnet_model.evaluate(Xt, yt, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\"\"\""
      ],
      "metadata": {
        "id": "l4dt5shiosnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rQX2XYhJ0bQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"#Creamos el modelo\n",
        "def preprocess_data(X, Y):\n",
        "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "    X_p = preprocess_input(X)\n",
        "    Y_p = keras.utils.to_categorical(Y, 10)\n",
        "    return X, Y_p\n",
        "\n",
        "resnet_model = build_resnet_encoder((32, 32, 3), 10)\n",
        "\n",
        "X, y = preprocess_data(Xtrain, ytrain)\n",
        "X, Xv, y, yv = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(X)\n",
        "\n",
        "#Define callbacks\n",
        "#Save the best model\n",
        "dirname = os.getcwd()\n",
        "filepath = os.path.join(dirname, 'pretrained_resnet10')\n",
        "filepath = os.path.join(filepath, 'model')\n",
        "\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
        "    mode='min', verbose = 0, save_best_only=True, save_weights_only=True)\n",
        "#Add early stopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose = 0)\n",
        "#Reduce learning rate on plateau\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.65, patience=5, min_lr=0.000001, verbose=1)\n",
        "\n",
        "callbacks = [model_checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "#Compile and fit the model\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = resnet_model.fit_generator(datagen.flow(X, y, batch_size=128), steps_per_epoch = len(X) / 128, epochs=200, validation_data=(Xv, yv), callbacks=callbacks)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "\n",
        "resnet_model.load_weights(filepath)\n",
        "\n",
        "Xt, yt = preprocess_data(Xtest, ytest)\n",
        "\n",
        "ypredict = resnet_model.predict(Xt)\n",
        "#ypredict = tf.squeeze(ypredict).numpy()\n",
        "#print(ypredict)\n",
        "#ypredict_round = [round(x) for x in ypredict]\n",
        "score = resnet_model.evaluate(Xt, yt, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkoQYIgWjIDN"
      },
      "source": [
        "# Entrenamos los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKEl35uijQ4F"
      },
      "outputs": [],
      "source": [
        "os.mkdir('embedding_images')\n",
        "create_db('cifar10_rnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8NzCLgvjIDN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Modelos con conv encoder para Cifar10\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, EfficientNetModel, 32, 'embedding_efficient32', 'cifar10_rnn', 'embedding_efficient32', keras.applications.efficientnet.preprocess_input, True, num_iterations=1, RGB=True)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, EfficientNetModel, 10, 'embedding_efficient10', 'cifar10_rnn', 'embedding_efficient10', keras.applications.efficientnet.preprocess_input, True, num_iterations=1, RGB=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJpOPFaDOQQ4"
      },
      "outputs": [],
      "source": [
        "\"\"\"ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, ResNetModel, 32, 'embedding_resnet', 'cifar10_rnn', 'embedding_resnet32', preprocess_input, True, num_iterations=1, RGB=True)\n",
        "run_model(Xtrain, ytrain, Xtest, ytest, ResNetModel, 10, 'embedding_resnet', 'cifar10_rnn', 'embedding_resnet10', preprocess_input, True, num_iterations=1, RGB=True)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZ0bMBqjIDO"
      },
      "source": [
        "# Ploteamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByranKy-jIDP"
      },
      "outputs": [],
      "source": [
        "plot_db_columns('cifar10_rnn', 'Cifar10 model accuracy', 'Strip size', 'Accuracy', 'cifar10_rnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYvW2KF1h1Sf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "cifar10_rnn.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}